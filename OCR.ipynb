{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "OCR final.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tejaskarnani/OCR-digit/blob/master/OCR.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SRK0M5oyBSGB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn import datasets"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VOav42Dt6_pM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "digits = datasets.load_digits()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2uvJDFMcJezY",
        "colab_type": "text"
      },
      "source": [
        "Loads a 3D array using the datasets function from the sklearn module.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qCAep1uk7bZi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c1d46091-69ac-4e67-bea6-09e8e3eabf66"
      },
      "source": [
        "digits.images.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1797, 8, 8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JgNEp_DmJPke",
        "colab_type": "text"
      },
      "source": [
        "Represents the dimensions of the 3D array digits.images, which contains binary representations of all digits\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jTTqzO-D7g5x",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "ffa3f187-1c04-49a3-8328-8a9b2952efd0"
      },
      "source": [
        "print (digits.images[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 0.  0.  5. 13.  9.  1.  0.  0.]\n",
            " [ 0.  0. 13. 15. 10. 15.  5.  0.]\n",
            " [ 0.  3. 15.  2.  0. 11.  8.  0.]\n",
            " [ 0.  4. 12.  0.  0.  8.  8.  0.]\n",
            " [ 0.  5.  8.  0.  0.  9.  8.  0.]\n",
            " [ 0.  4. 11.  0.  1. 12.  7.  0.]\n",
            " [ 0.  2. 14.  5. 10. 12.  0.  0.]\n",
            " [ 0.  0.  6. 13. 10.  0.  0.  0.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B8URDrCQJNXj",
        "colab_type": "text"
      },
      "source": [
        "The binary representation of the image present at index 0 in the array digits. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tocV6LJs8I1N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Imw5s2Xy8W_o",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "outputId": "8b2d4a4e-c027-4857-8f61-6f2807cef043"
      },
      "source": [
        "plt.imshow(digits.images[0], cmap = \"binary\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f32b2b5eac8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GGTC7KkpLP0r",
        "colab_type": "text"
      },
      "source": [
        "The image of the first element of the dataset, which we can see is a 0. Notice that we can also come to a rough estimation using the binary representation, considering 0s as white spaces, and larger integers as dark pixels."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-MSMbvjU9DOC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 862
        },
        "outputId": "ed9f4fef-abc7-412a-a00b-8cb5c03a83a4"
      },
      "source": [
        "def plot_multi(i):\n",
        "  '''Plots 16 digits, starting with digit i'''\n",
        "  nplots = 16\n",
        "  fig = plt.figure(figsize=(15,15))\n",
        "  for j in range(nplots):\n",
        "    plt.subplot(4,4,j+1)\n",
        "    plt.imshow(digits.images[i+j], cmap='binary')\n",
        "    plt.title(digits.target[i+j])\n",
        "    plt.axis('off')\n",
        "  plt.show()\n",
        "\n",
        "plot_multi(0)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1080x1080 with 16 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rwj-_6HVLwxP",
        "colab_type": "text"
      },
      "source": [
        "This data, detailing the correct digit (on top of the image) corresponding to each image, is included with the dataset. We will use this data for the training of the system."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9yXcAC8I96Ej",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "3e4411e0-b643-4bbb-8c2a-290532f52098"
      },
      "source": [
        "y = digits.target\n",
        "print(y.shape)\n",
        "x = digits.images.reshape((len(digits.images), -1))\n",
        "x.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1797,)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1797, 64)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mm5AdtS6Q_Ne",
        "colab_type": "text"
      },
      "source": [
        "The x array consisits of the images, whereas the y array consists of the corresponding correct digits."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wmgEZrPP_G9k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train = x[:1000]\n",
        "y_train = y[:1000]\n",
        "x_test = x[1000:]\n",
        "y_test = y[1000:]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0FaT_Lw1N4_9",
        "colab_type": "text"
      },
      "source": [
        "The x and y arrays are split into two for training and testing- in that order.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MJrVAvcEA2BX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.neural_network import MLPClassifier"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kTsrQfg-Eb-Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mlp = MLPClassifier(hidden_layer_sizes=(15,), activation='logistic', alpha=1e-4,\n",
        "solver='sgd', tol=1e-4, random_state=1,\n",
        "learning_rate_init=.1, verbose=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y5zX3ajvOJRh",
        "colab_type": "text"
      },
      "source": [
        "MLPClassifier from scikit-learn offers several ML models, and here, I have used the simple Linear Regression Model, which I have also have worked with in my Math courses at school. Each of these variables can be tweaked for a wide range of purposes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q1xUwmHTE4UV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "b03c4333-b216-45b5-d8d3-0d5541bef358"
      },
      "source": [
        "mlp.fit(x_train,y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Iteration 1, loss = 2.22958289\n",
            "Iteration 2, loss = 1.91207743\n",
            "Iteration 3, loss = 1.62507727\n",
            "Iteration 4, loss = 1.32649842\n",
            "Iteration 5, loss = 1.06100535\n",
            "Iteration 6, loss = 0.83995513\n",
            "Iteration 7, loss = 0.67806075\n",
            "Iteration 8, loss = 0.55175832\n",
            "Iteration 9, loss = 0.45840445\n",
            "Iteration 10, loss = 0.39149735\n",
            "Iteration 11, loss = 0.33676351\n",
            "Iteration 12, loss = 0.29059880\n",
            "Iteration 13, loss = 0.25437208\n",
            "Iteration 14, loss = 0.22838372\n",
            "Iteration 15, loss = 0.20200554\n",
            "Iteration 16, loss = 0.18186565\n",
            "Iteration 17, loss = 0.16461183\n",
            "Iteration 18, loss = 0.14990228\n",
            "Iteration 19, loss = 0.13892154\n",
            "Iteration 20, loss = 0.12833784\n",
            "Iteration 21, loss = 0.12138920\n",
            "Iteration 22, loss = 0.11407971\n",
            "Iteration 23, loss = 0.10677664\n",
            "Iteration 24, loss = 0.10037149\n",
            "Iteration 25, loss = 0.09593187\n",
            "Iteration 26, loss = 0.09250135\n",
            "Iteration 27, loss = 0.08676698\n",
            "Iteration 28, loss = 0.08356043\n",
            "Iteration 29, loss = 0.08209789\n",
            "Iteration 30, loss = 0.07649168\n",
            "Iteration 31, loss = 0.07410898\n",
            "Iteration 32, loss = 0.07126869\n",
            "Iteration 33, loss = 0.06926956\n",
            "Iteration 34, loss = 0.06578496\n",
            "Iteration 35, loss = 0.06374913\n",
            "Iteration 36, loss = 0.06175492\n",
            "Iteration 37, loss = 0.05975664\n",
            "Iteration 38, loss = 0.05764485\n",
            "Iteration 39, loss = 0.05623663\n",
            "Iteration 40, loss = 0.05420966\n",
            "Iteration 41, loss = 0.05413911\n",
            "Iteration 42, loss = 0.05256140\n",
            "Iteration 43, loss = 0.05020265\n",
            "Iteration 44, loss = 0.04902779\n",
            "Iteration 45, loss = 0.04788382\n",
            "Iteration 46, loss = 0.04655532\n",
            "Iteration 47, loss = 0.04586089\n",
            "Iteration 48, loss = 0.04451758\n",
            "Iteration 49, loss = 0.04341598\n",
            "Iteration 50, loss = 0.04238096\n",
            "Iteration 51, loss = 0.04162200\n",
            "Iteration 52, loss = 0.04076839\n",
            "Iteration 53, loss = 0.04003180\n",
            "Iteration 54, loss = 0.03907774\n",
            "Iteration 55, loss = 0.03815565\n",
            "Iteration 56, loss = 0.03791975\n",
            "Iteration 57, loss = 0.03706276\n",
            "Iteration 58, loss = 0.03617874\n",
            "Iteration 59, loss = 0.03593227\n",
            "Iteration 60, loss = 0.03504175\n",
            "Iteration 61, loss = 0.03441259\n",
            "Iteration 62, loss = 0.03397449\n",
            "Iteration 63, loss = 0.03326990\n",
            "Iteration 64, loss = 0.03305025\n",
            "Iteration 65, loss = 0.03244893\n",
            "Iteration 66, loss = 0.03191504\n",
            "Iteration 67, loss = 0.03132169\n",
            "Iteration 68, loss = 0.03079707\n",
            "Iteration 69, loss = 0.03044946\n",
            "Iteration 70, loss = 0.03005546\n",
            "Iteration 71, loss = 0.02960555\n",
            "Iteration 72, loss = 0.02912799\n",
            "Iteration 73, loss = 0.02859103\n",
            "Iteration 74, loss = 0.02825959\n",
            "Iteration 75, loss = 0.02788968\n",
            "Iteration 76, loss = 0.02748725\n",
            "Iteration 77, loss = 0.02721247\n",
            "Iteration 78, loss = 0.02686225\n",
            "Iteration 79, loss = 0.02635636\n",
            "Iteration 80, loss = 0.02607439\n",
            "Iteration 81, loss = 0.02577613\n",
            "Iteration 82, loss = 0.02553642\n",
            "Iteration 83, loss = 0.02518749\n",
            "Iteration 84, loss = 0.02484300\n",
            "Iteration 85, loss = 0.02455379\n",
            "Iteration 86, loss = 0.02432480\n",
            "Iteration 87, loss = 0.02398548\n",
            "Iteration 88, loss = 0.02376004\n",
            "Iteration 89, loss = 0.02341261\n",
            "Iteration 90, loss = 0.02318255\n",
            "Iteration 91, loss = 0.02296065\n",
            "Iteration 92, loss = 0.02274048\n",
            "Iteration 93, loss = 0.02241054\n",
            "Iteration 94, loss = 0.02208181\n",
            "Iteration 95, loss = 0.02190861\n",
            "Iteration 96, loss = 0.02174404\n",
            "Iteration 97, loss = 0.02156939\n",
            "Iteration 98, loss = 0.02119768\n",
            "Iteration 99, loss = 0.02101874\n",
            "Iteration 100, loss = 0.02078230\n",
            "Iteration 101, loss = 0.02061573\n",
            "Iteration 102, loss = 0.02039802\n",
            "Iteration 103, loss = 0.02017245\n",
            "Iteration 104, loss = 0.01997162\n",
            "Iteration 105, loss = 0.01989280\n",
            "Iteration 106, loss = 0.01963828\n",
            "Iteration 107, loss = 0.01941850\n",
            "Iteration 108, loss = 0.01933154\n",
            "Iteration 109, loss = 0.01911473\n",
            "Iteration 110, loss = 0.01905371\n",
            "Iteration 111, loss = 0.01876085\n",
            "Iteration 112, loss = 0.01860656\n",
            "Iteration 113, loss = 0.01848655\n",
            "Iteration 114, loss = 0.01834844\n",
            "Iteration 115, loss = 0.01818981\n",
            "Iteration 116, loss = 0.01798523\n",
            "Iteration 117, loss = 0.01783630\n",
            "Iteration 118, loss = 0.01771441\n",
            "Iteration 119, loss = 0.01749814\n",
            "Iteration 120, loss = 0.01738339\n",
            "Iteration 121, loss = 0.01726549\n",
            "Iteration 122, loss = 0.01709638\n",
            "Iteration 123, loss = 0.01698340\n",
            "Iteration 124, loss = 0.01684606\n",
            "Iteration 125, loss = 0.01667016\n",
            "Iteration 126, loss = 0.01654172\n",
            "Iteration 127, loss = 0.01641832\n",
            "Iteration 128, loss = 0.01630111\n",
            "Iteration 129, loss = 0.01623051\n",
            "Iteration 130, loss = 0.01612736\n",
            "Iteration 131, loss = 0.01590220\n",
            "Iteration 132, loss = 0.01582485\n",
            "Iteration 133, loss = 0.01571372\n",
            "Iteration 134, loss = 0.01560349\n",
            "Iteration 135, loss = 0.01557688\n",
            "Iteration 136, loss = 0.01534420\n",
            "Iteration 137, loss = 0.01527883\n",
            "Iteration 138, loss = 0.01517545\n",
            "Iteration 139, loss = 0.01503663\n",
            "Iteration 140, loss = 0.01501192\n",
            "Iteration 141, loss = 0.01482535\n",
            "Iteration 142, loss = 0.01471388\n",
            "Iteration 143, loss = 0.01463948\n",
            "Iteration 144, loss = 0.01454059\n",
            "Iteration 145, loss = 0.01441742\n",
            "Iteration 146, loss = 0.01431741\n",
            "Iteration 147, loss = 0.01428414\n",
            "Iteration 148, loss = 0.01416364\n",
            "Iteration 149, loss = 0.01406742\n",
            "Iteration 150, loss = 0.01402651\n",
            "Iteration 151, loss = 0.01389720\n",
            "Iteration 152, loss = 0.01381412\n",
            "Iteration 153, loss = 0.01371300\n",
            "Iteration 154, loss = 0.01362465\n",
            "Iteration 155, loss = 0.01357048\n",
            "Iteration 156, loss = 0.01348760\n",
            "Iteration 157, loss = 0.01339543\n",
            "Iteration 158, loss = 0.01331941\n",
            "Iteration 159, loss = 0.01320812\n",
            "Iteration 160, loss = 0.01315415\n",
            "Iteration 161, loss = 0.01308279\n",
            "Iteration 162, loss = 0.01302708\n",
            "Iteration 163, loss = 0.01290042\n",
            "Iteration 164, loss = 0.01289267\n",
            "Iteration 165, loss = 0.01277558\n",
            "Iteration 166, loss = 0.01277238\n",
            "Iteration 167, loss = 0.01261308\n",
            "Iteration 168, loss = 0.01260611\n",
            "Iteration 169, loss = 0.01248789\n",
            "Iteration 170, loss = 0.01239662\n",
            "Iteration 171, loss = 0.01231743\n",
            "Iteration 172, loss = 0.01227346\n",
            "Iteration 173, loss = 0.01223136\n",
            "Iteration 174, loss = 0.01217211\n",
            "Iteration 175, loss = 0.01208682\n",
            "Iteration 176, loss = 0.01204707\n",
            "Iteration 177, loss = 0.01200225\n",
            "Iteration 178, loss = 0.01188677\n",
            "Iteration 179, loss = 0.01184993\n",
            "Iteration 180, loss = 0.01175130\n",
            "Iteration 181, loss = 0.01171178\n",
            "Iteration 182, loss = 0.01166052\n",
            "Iteration 183, loss = 0.01163843\n",
            "Iteration 184, loss = 0.01154892\n",
            "Iteration 185, loss = 0.01147629\n",
            "Iteration 186, loss = 0.01142365\n",
            "Iteration 187, loss = 0.01136608\n",
            "Iteration 188, loss = 0.01128053\n",
            "Iteration 189, loss = 0.01128869\n",
            "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MLPClassifier(activation='logistic', alpha=0.0001, batch_size='auto',\n",
              "              beta_1=0.9, beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
              "              hidden_layer_sizes=(15,), learning_rate='constant',\n",
              "              learning_rate_init=0.1, max_fun=15000, max_iter=200, momentum=0.9,\n",
              "              n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
              "              random_state=1, shuffle=True, solver='sgd', tol=0.0001,\n",
              "              validation_fraction=0.1, verbose=True, warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h_NNwERiOisH",
        "colab_type": "text"
      },
      "source": [
        "Using the Model we have defined before, and the corresponding x and y training arrays, the computer is trained. As it prints out, the model stops when the training loss does not improve beyond a set point (defined in the model)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FnGtDNkaIMj-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "prediction = mlp.predict(x_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6BddJRrcJ1-u",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ba032214-c378-474b-836f-f7e112557c48"
      },
      "source": [
        "prediction.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(797,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vYHUBcrHPN9p",
        "colab_type": "text"
      },
      "source": [
        "The array prediction contains 797 elements. (Equal to x_test and y_test)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hKZLShWnJ5Vx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "e53b2f88-44ee-48e3-cf99-b77fa423e7fc"
      },
      "source": [
        "prediction[:50]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 4, 0, 5, 3, 6, 9, 6, 1, 7, 5, 4, 4, 7, 2, 8, 2, 2, 5, 7, 9, 5,\n",
              "       4, 4, 9, 0, 8, 9, 8, 0, 1, 2, 3, 4, 5, 6, 7, 8, 3, 0, 1, 2, 3, 4,\n",
              "       5, 6, 7, 8, 5, 0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_GHj8S4iPDoA",
        "colab_type": "text"
      },
      "source": [
        "This is the array of the first 50 predicted digits using the ML model\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6kplVSUmKKU2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "3f4f338f-6480-4868-9e9c-03ea2a393fe1"
      },
      "source": [
        "y_test[:50]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 4, 0, 5, 3, 6, 9, 6, 1, 7, 5, 4, 4, 7, 2, 8, 2, 2, 5, 7, 9, 5,\n",
              "       4, 4, 9, 0, 8, 9, 8, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 0, 1, 2, 3, 4,\n",
              "       5, 6, 7, 8, 9, 0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ycnv23eXPJ24",
        "colab_type": "text"
      },
      "source": [
        "The correct answers for the corresponding 50 digits."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YJS-5OXYKQZr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "diff = prediction - y_test"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OdHmhjQFPll7",
        "colab_type": "text"
      },
      "source": [
        "`diff` is the difference in the predicted digits and the actual digits (for the entire sets)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GBS3Qt2ZNsbb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "8f0faf01-af67-4d8f-ef2c-cfa80ff38c6e"
      },
      "source": [
        "c = 0\n",
        "for i in range (0,797):\n",
        "  if diff[i] != 0:\n",
        "    c += 1\n",
        "print (\"The accuracy of this model is \",1 - (c/797))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The accuracy of this model is  0.9146800501882058\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gKXYNZsFOpIn",
        "colab_type": "text"
      },
      "source": [
        "Using the simple formula to calculate accuracy of a ML model, we find that this model gives a **91.47 % accuracy**"
      ]
    }
  ]
}